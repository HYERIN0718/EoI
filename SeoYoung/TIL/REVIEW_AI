*** 활성화함수 ***
1) 시그모이드
2) 계단 함수
시그모이드와 계단함수는 비선형함수이다.
3) ReLU 함수 : 입력이 0을 넘으면 그 입력을 그대로 출력하고, 0 이하이면 0을 출력
4) 항등함수 : 입력을 그대로 출력
5) 소프트맥스 함수 : 
- 소프트맥스의 출력은 모든 입력 신호로부터 회살표를 받는다. (출력층의 각 뉴런이 모든 입력 신호에서 영향 받음)
- 컴퓨터로 구현 시 오버플로 문제 주의
- 소프트맥스 함수의 출력은 0과 1.0 사이의 실수 => 출력 총합이 1 => 확률로 해석 가능


*** 배치 ***
: 하나로 묶은 입력 데이터
: 데이터를 배치로 처리함으로써 효율적이고 빠르게 처리 ㄱㄴ

신경망의 특징은 데이터를 보고 학습 가능하다는 점. 즉, 가중치 매개변수의 값을 데이터를 보고 자동으로 결정.
데이터를 훈련 데이터와 시험 데이터로 나누어 학습과 실험 수행.

*** 손실 함수 ***
신경망은 하나의 지표를 기준으로 최적의 매개변수 값을 탐색한다. 이 때 사용하는 지표가 손실함수.
1) 평균 제곱 오차
2) 교차 엔트로피 오치

